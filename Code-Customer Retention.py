# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lEVoSSvqu04_8mGiGWU4M-iz71FrlrFy

The goal of the project-
To predict which donors are at risk of discontinuing their donations (churn) based on historical donation data and engagement records.
Running the model on limited technical resources, so the model must prioritize
efficiency, clarity, and the ability to drive actionable outcomes

Appraoch:
My appraoch for this assignment was to start with basic- get to know the data what are the columns, what each column signifies and what are unique values in each column. Secondly, checking for missing values, outlier, duplicates. If they are present, simply imputing it with best appraoch. As the data was just of 10000 rows, I decided to stick to imputation rather than dropping it as I believe that each row can tell you something and can utlimately add to accuracy.
Next, feature engineering creating new column if necessary- here we created new column month since last donation because it can tell lot about the target variable churned. Followed feature engineering with data encoding, used different encoding method for each type of column. like for categorical used one hot encoding, and for binary column suggestion action taken or not imputed with 0 assuming no action taken and lastly for numerical column imputed with appropriate appraoch. Before, going to building the model, while doing the data exploration I noticed that there is no target variable and this is the supervised machine learning problem of classification. So for that created target variable. Ultimately the last step is building machine learning model, used PCA for overfitting to make sure that it works well on unseen data. Using different ML model to built the model. following that I also did the evaluation to select which ML model will work well in simple, effective and performance efficient way.

Steps:
1. Data Loading
2. Data Exploration
3. Data Cleaning
4. Feature Engineering
5. Data Pre Processing
6. Model Building
7. Model Evaluation
"""

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.decomposition import PCA

"""Data Loading"""

# Loading the data
df = pd.read_excel("donor_data.xlsx")

# Display the first few rows to understand the structure of the data
#Checking if the data is loaded in proper format
df.head()

"""The dataset contains 10 columns:
•	DonorID: Unique identifier for each donor.
•	DonationAmount: The amount donated by the donor.
•	DonationFrequency: Frequency of donations (monthly, quarterly, yearly).
•	LastDonationDate: Date of the donor's most recent donation.
•	Age: Age of the donor.
•	IncomeRange: Categorized income levels (high, medium, low).
•	EventParticipation: Binary indicator of whether the donor participated in fundraising events.
•	NewsletterOpen: Binary indicator of whether the donor opened newsletters.
•	EmailClicks: Binary indicator of whether the donor clicked on emails.
•	CommunicationPreference: The preferred mode of contact for the donor (email, phone, or mail).

Data Exploration
"""

# To see how many rows and columns are there in dataset
df.shape

#To see statitstical information like mean, mode, median, max values, 25% percentile, 75% percentile and other info
df.describe

"""Data Cleaning"""

# Checking for missing value and getting the sum of missing values in each column
missing_values = df.isnull().sum()

# Significant amount of missing values in DonationAmount, Eventparticipation
#NewletterOpens, EmailClicks, CommunicationPreference

#To see statitstical information like mean, mode, median, max values, 25% percentile, 75% percentile and other info
#To know more about each column
basic_stats = df.describe(include='all').transpose()

# Printing the missing values and basic statistics
missing_values, basic_stats

# Checking for duplicates
duplicates = df.duplicated()
print(f"Number of duplicate rows: {duplicates.sum()}")

# Checking for two extreme values in each numeric features
range_values = df.describe().loc[['min', 'max']]
print("Range of Values for Numeric Columns:")
print(range_values)

# Lets see the count of each age
sns.histplot(df['Age'], kde=True, bins=30)
plt.title("Age Distribution Before Cleaning")
plt.show()

# There are significant number of outlier as age cannot be less than 0 and more than 100

df['Age'].min()

df['Age'].max()

#From the stats, min age is -5 and max is 200
#which is not possible to have
# so clipping the outliers to median value
#median imputation is not sensitive to outliers
df['Age'] = df['Age'].apply(lambda x: x if 0 < x < 100 else df['Age'].median())

df['Age'].min()

df['Age'].max()

# Check the distribution of Age for outliers
sns.histplot(df['Age'], kde=True, bins=30)
plt.title("Age Distribution After Cleaning")
plt.show()

#This chart shows the distribution of the Age feature after cleaning.
#The data now appears uniformly distributed across most age ranges,
#with a noticeable peak around the median age of 50.

"""Feature Engineering"""

# So we need to know how many days have been passed since the donor has done donation
#So if days passed since last donation  is more than their expected cycle that means the donar is churned
# Convert LastDonationDate to datetime and calculate "DaysSinceLastDonation"
from datetime import datetime
#lastDonationDate is in object type so converted it to datetime
df['LastDonationDate'] = pd.to_datetime(df['LastDonationDate'], errors='coerce')

# Convert LastDonationDate to datetime and calculate "DaysSinceLastDonation"
df['DaysSinceLastDonation'] = (datetime.now() - df['LastDonationDate']).dt.days

# Filling the numerical column DonationAmount by median as there are extreme values from 10 to 999
# Avoid the extremeness imputed with median
# median imputation will ultimately add the value that is at the middle when arranged in ascending order
# For numerical columns: use median
numerical_cols = ['DonationAmount']
for col in numerical_cols:
    df[col].fillna(df[col].median(), inplace=True)

# Similarly for binary columns with values 1 or 0
#imputed with 0 assuming that no action took place
binary_cols = ['EventParticipation', 'NewsletterOpens', 'EmailClicks']
for col in binary_cols:
    df[col].fillna(0, inplace=True)

# For categorical columns: use the most frequent value
# Using mode here, like whatever is the common method that most people prefer
#Filling NAN values with most preferred method
categorical_cols = ['CommunicationPreference']
for col in categorical_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)

# Graph was plotted to examine the distribution of donations across different months
#Trend Analysis
df['LastDonationMonth'] = df['LastDonationDate'].dt.month
sns.countplot(x='LastDonationMonth', data=df)
plt.title('Monthly Donation Trends')
plt.show()

#The graph shows consistent donor engagement across all months, with slight peaks in March, July, and December.
#Efforts should focus on amplifying these peaks through targeted campaigns while maintaining stable engagement
#year-round.

"""Data Pre-Processing"""

# The ML model does not run on categorical variable
# So for that I converted categories into numerical
# Encode categorical columns using one-hot encoding
# One hot encoding will try to add a spearate column for each category and the value will be based on the value in the column
# example if donor do yearly donation so for donation frequency yearly frequency the value will be true and for other category it will be False
# Similarly for other categories

encoded_df = pd.get_dummies(df, columns=['DonationFrequency', 'IncomeRange', 'CommunicationPreference'], drop_first=True)

# Now Donor ID and Last Donation date are not relevant for predicting whether the customer will be churned or not
#So droping those two columns

processed_df = encoded_df.drop(columns=['DonorID', 'LastDonationDate'])

# Check the processed data
processed_df.head()

pip install imbalanced-learn

# Check the target variable distribution (assuming it's a binary column like 'Churned')
# Placeholder: For now, add a dummy target variable for demonstration

processed_df['Churned'] = np.random.choice([0, 1], size=len(processed_df), p=[0.8, 0.2])

# Let see how is the distrubution for churned category in label
# Checking if dataset is balanced or not
#Balanced means whether each category are in same or almost same proportion or not

class_distribution = processed_df['Churned'].value_counts(normalize=True)
class_distribution

#To analyze the relationship between AgeGroup and Churn to identify patterns in
# donor retention across different age segments.
# Ensure 'AgeGroup' is added to processed_df
processed_df['AgeGroup'] = pd.cut(df['Age'], bins=[20, 40, 60, 80, 100], labels=['20-40', '40-60', '60-80', '80+'])

# Plotting Churn by Age Group
sns.countplot(x='AgeGroup', hue='Churned', data=processed_df)
plt.title('Churn by Age Group')
plt.show()

"""This graph reveals that middle-aged and older donors (40-80) are the most loyal, with lower churn rates compared to younger donors (20-40), who exhibit higher relative churn. Donors aged 80+ are fewer in number but seem to churn less, likely due to sample size. Retention efforts should focus on engaging younger donors through personalized campaigns, flexible donation options, and impactful communication. Middle-aged donors should receive consistent retention efforts to maintain their strong loyalty. This segmentation can guide targeted strategies to improve overall donor retention."""

#the box plots show that the median donation amounts are fairly consistent across
# frequencies, but churned donors (orange) generally exhibit slightly higher variability
# in donation amounts, particularly in the yearly group. This indicates that donors contributing
# yearly might be more prone to churn despite contributing similar amounts on average,
# highlighting the need for targeted retention strategies for this group.

processed_df = processed_df.drop(columns=['AgeGroup'])

#Creating X and Y set
# X contains all the feature that are necessary for predicting Y
# Y contains the label data which is churned or not
# Basically Separating features and target
X = processed_df.drop(columns=['Churned'])
y = processed_df['Churned']

# Correlation Matrix for Numerical Features
correlation_matrix = processed_df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix of Numerical Features")
plt.show()

#Few features have more correlation over other
#Features like communicationpreference_phone, incomerange_low, DaysSinceLastDonation, Donation frequency_quaterly

X.info()

# Missing values so imputing with median
X.fillna(X.median(), inplace=True)  # Impute missing values with the median

# Split the data into training and test sets with 80:20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

#Numerical columns like donation amount, monthsincedonation and age are in different scales
# If we run without treating and bringing it in same scale
# The model will be more baised towards the higher number variable
# So for balancing it doing Scaling
# Scale numerical features for better model performance
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# There are imbalance in set so balancing it with SMOTE
# SMOTE creates more instance for minority class
# Reduces biases
# Apply SMOTE to address class imbalance

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)

# Checking the resampled class distribution

resampled_class_distribution = pd.Series(y_train_resampled).value_counts(normalize=True)
resampled_class_distribution

# Balance between the categories of churned or not

"""Model Building & Evaluation

Accuracy: How accurately it is classifying the target category
Precision: Positive prediction that was actually correct
Recall: Prediction that are actual true to that of total number of positive
ROC: shows graph for performance of model for different threshold
AUC: area under ROC
AUC and ROC are used to measure how well prediction are ranked than their absolute mean.
"""

from sklearn.tree import DecisionTreeClassifier

# Train Decision Tree model
dt_model = DecisionTreeClassifier(random_state=42, class_weight='balanced')
dt_model.fit(X_train_scaled, y_train)

# Predictions and evaluations for Decision Tree
dt_preds = dt_model.predict(X_test_scaled)

# Generate and print classification report
dt_report = classification_report(y_test, dt_preds, target_names=["Not Churned", "Churned"])
print("Classification Report for Decision Tree Model:\n")
print(dt_report)

# Compute ROC-AUC score
dt_auc = roc_auc_score(y_test, dt_model.predict_proba(X_test_scaled)[:, 1])
print(f"ROC-AUC Score for Decision Tree Model: {dt_auc:.4f}")

#Decision Tree Classifer
# Accuracy:  68%
# Precision: 68%
# Recall: 49%
# ROC-AUC: 49%

# Feature Importance for Decision Tree
dt_feature_importance = pd.Series(dt_model.feature_importances_, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(10, 6))
dt_feature_importance.plot(kind='bar')
plt.title("Feature Importance (Decision Tree)")
plt.show()

# DonationAmount, DayssinceDonation and Age is significant feature

# Lets build Logistic regression for non linear features
from sklearn.linear_model import LogisticRegression

# Train Logistic Regression model
logistic_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)
logistic_model.fit(X_train_scaled, y_train)

# Predictions and evaluations for Logistic Regression
logistic_preds = logistic_model.predict(X_test_scaled)

# Generate and print classification report
logistic_report = classification_report(y_test, logistic_preds, target_names=["Not Churned", "Churned"])
print("Classification Report for Logistic Regression Model:\n")
print(logistic_report)

# Compute ROC-AUC score
logistic_auc = roc_auc_score(y_test, logistic_model.predict_proba(X_test_scaled)[:, 1])
print(f"ROC-AUC Score for Logistic Regression Model: {logistic_auc:.4f}")

#Logistic Regression Classifer
# Accuracy:  50%
# Precision: 69%
# Recall: 50%
# ROC-AUC: 52%

# Lets build Randomforest Classifier
# To work on accuracy and ensuring accurate result
# Exhaust resources
from sklearn.ensemble import RandomForestClassifier

# Train Random Forest model
rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100)
rf_model.fit(X_train_scaled, y_train)

# Predictions and evaluations for Random Forest
rf_preds = rf_model.predict(X_test_scaled)

# Generate and print classification report
rf_report = classification_report(y_test, rf_preds, target_names=["Not Churned", "Churned"])
print("Classification Report for Random Forest Model:\n")
print(rf_report)

# Compute ROC-AUC score
rf_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test_scaled)[:, 1])
print(f"ROC-AUC Score for Random Forest Model: {rf_auc:.4f}")

#Random Forest Classifer
# Accuracy:  80%
# Precision: 67%
# Recall: 80%
# ROC-AUC: 50%

# Feature Importance for Random Forest
rf_feature_importance = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(10, 6))
rf_feature_importance.plot(kind='bar')
plt.title("Feature Importance (Random Forest)")
plt.show()

# DonationAmount, DayssinceDonation and Age is significant feature

# Lets build SVM model and train it
# SVM is resource efficient

from sklearn.svm import SVC

# Train SVM model with probability enabled
svm_model = SVC(random_state=42, class_weight='balanced', probability=True)
svm_model.fit(X_train_scaled, y_train)

# Predictions and evaluations for SVM
svm_preds = svm_model.predict(X_test_scaled)

# Generate and print classification report
svm_report = classification_report(y_test, svm_preds, target_names=["Not Churned", "Churned"])
print("Classification Report for SVM Model:\n")
print(svm_report)

# Compute ROC-AUC score
svm_auc = roc_auc_score(y_test, svm_model.predict_proba(X_test_scaled)[:, 1])
print(f"ROC-AUC Score for SVM Model: {svm_auc:.4f}")

#Support Vector Machine Classifer
# Accuracy:  53%
# Precision: 67%
# Recall: 53%
# ROC-AUC: 51%

#Lets see how decision tree performs without feature engineering

"""Accuracy:
1.  Decision Tree: 68%
2.  Logistic Regression: 50%
3.  Random Forest: 79%
4.  SVM: 51%

These models keeping in mind the non-linearity in the dataset were selected also these model are simple, proficient, and easy to interpret, catering to the needs of a limited-resource organization. **Random forest** was chosen as there are multiple significant features that are leading to decision or whether the donor will be churned or not. Along with this it is easy to use, gives clear insights, and low computational cost, making it ideal for non-technical teams. Logistic Regression was included as a baseline due to its simplicity and efficiency, while **Decision Tree** was tested for its robust accuracy and ability to handle complex patterns but didnt go much accuracy. SVM was explored for its capability with non-linear data, though it proved less effective here. Together, these models provide a comprehensive evaluation to identify the best fit for the organization’s needs.

Significant model: Random forest with 80% accuracy.
Siginficant feature: DonationAmount, DayssinceDonation and Age is significant feature
"""